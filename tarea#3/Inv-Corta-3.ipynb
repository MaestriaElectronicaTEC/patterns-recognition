{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "![cover.jpg](attachment:cover.jpg)\n",
    "\n",
    "One of the biggest challenges with the Deep Learning algorithms is the need of a huge amount of data in order to achieve a good performance. With the rise of Reinforcement Learning this limitation can be overcome in some way. But the idea of the RL is not new; in fact it was proposed first time in 1980s by Rich Sutton and Andrew Barto, but is till know that the technology has allowed its implementation. This guide will develop first a brief introduction of the definition and key concepts behind RL, then the types of RL algorithms will be mentioned, continuing with an introduction to the use the the Gym framework for Python in a simple example of RL and finally a breif presentation of success use cases.\n",
    "\n",
    "## Origins of Reinforcement Learning\n",
    "\n",
    "In order to understand the Reinforcement Lerning concept, is important to mention the roots of this idea. To do that we have to review the Behavioral Psychology theory, that comes from the psicology field. This theory states that the bahavior of humans and animals is consequence of the experience in certain environment. Let's present a very simple example of this reward-driven behavior idea.\n",
    "\n",
    "Imagine that you are training your dog to do some trick. You have to show your dog what you pretend it to do, and the dog will act if some vary ways. If your dog do the trick tha you want, you will reward it with its favorite food. With this action we are incetivating, via a positive reinforcement, the performace of that trick. If you respond negatively to some behavior of the dog that does not lead to the trick, the dog probably will try to avoid it a next time.\n",
    "\n",
    "![]()\n",
    "<img src=\"attachment:dog_training.jpg\" width=\"400\">\n",
    "\n",
    "## Definition of Reinforcement Learning\n",
    "\n",
    "The basic idea of Reinforcement learging is adquire knowlege through interactions with a environment. We will have a RL agent that is interacting with its environment, till see some consequencies of its actions, the agent will adjust its behaviors if response of the reward received. This agent is handled by a machine learning algorithm and its objective is learn a policy that maximize the expected reward from the environment.\n",
    "\n",
    "### Markov Desition Process\n",
    "\n",
    "RL is modeled using the Markov Desition Process (MDP):\n",
    "* A group of **States**, with its corresponding distribution **p(S)**.\n",
    "* A group of **actions**.\n",
    "* Transitions dynamics.\n",
    "* An immediate reward function.\n",
    "* A discount factor.\n",
    "\n",
    "![rl_model.png](attachment:rl_model.png)\n",
    "\n",
    "Now, let's describe the key concepts in RL:\n",
    "\n",
    "* **Environment:** This is the place where the agent is and interact with.\n",
    "* **State:** Here is the description of the environment is some instant or period of time.\n",
    "* **Action:** This depends of the environment where the agent is.\n",
    "* **Reward:** It depends of the current state, the action performed and the next state. This component plays a very important role in the RL model, because it has to be tracked in orden to optimize the algorithm.\n",
    "* **Policies:** Set of rules used by the agents that defines the action to be taken.\n",
    "\n",
    "Going back to the dog training example, we can say that the dog is the agent, your house or the place where you are training it is the environment; the desciption of the place of the situacions in it, is the state; and then the dog will receive positive or negative rewards that will help it to learn the trick.\n",
    "\n",
    "## Types of Reinforcement Learning algorithms\n",
    "\n",
    "Exist two types of RL approaches: the policy search, value function and a hybrid called actor-critic.\n",
    "\n",
    "* **Value function:** In this approach the algorithm tries to estimate the expected return in given some state.\n",
    "* **Search policy:** In this case, the algorithm search for an optimal policiy directly, which becomes the case of a stochastic optimization.\n",
    "* **Actor-critic:** In this case the actor (policy) learns by using feedback from the critic (value function).\n",
    "\n",
    "![actor-critic.png](attachment:actor-critic.png)\n",
    "\n",
    "\n",
    "## Example of Reinforcement Learning using OpenAI gym\n",
    "\n",
    "To do a little demostration of the use of RL, we will make use of the [OpenAI gym](https://gym.openai.com/) tool for Python. So let's talk about this framework first. This is a toolkit that helps use in the implementation and verification of reinforcement learning algorithms\n",
    "\n",
    "To install it, you can use the Python Install Packages (**pip**), running the following command:\n",
    "\n",
    "```console\n",
    "pip install gym\n",
    "```\n",
    "Now let's run a very simple example using the **Sapce Invaders** Atari game as the environment and using the brute force as an estrategy for the action selection.\n",
    "\n",
    "> Maximize your score in the Atari 2600 game SpaceInvaders. In this environment, the observation is an RGB image of the screen, which is an array of shape (210, 160, 3) Each action is repeatedly performed for a duration of kk frames, where kk is uniformly sampled from \\{2, 3, 4\\}{2,3,4} (Source: https://gym.openai.com/envs/SpaceInvaders-v0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('SpaceInvaders-v0')\n",
    "env.reset()\n",
    "plt.figure(figsize=(9,9))\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "for _ in range(500):\n",
    "    img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning algorithm\n",
    "\n",
    "This is a simple and one of the most used algorithms in RL. The goal is to learn over the environment rewards. Here we will have a Q-Table with a map of the combination (state, action). This time the environment is the Frozen Lake.\n",
    "\n",
    "> The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile.\n",
    "(Source: https://gym.openai.com/envs/FrozenLake8x8-v0/)\n",
    "\n",
    "The following is the description of the surface:\n",
    "* S: starting point, safe.\n",
    "* F: frozen surface, safe.\n",
    "* H: hole, fall to your doom.\n",
    "* G: goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Sum on all episodes 0.001\n",
      "Final Values Q-Table\n",
      "[[0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.628 0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "# 1. Load Environment and Q-table structure\n",
    "env = gym.make('FrozenLake8x8-v0')\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "# env.obeservation.n, env.action_space.n gives number of states and action in env loaded\n",
    "# 2. Parameters of Q-leanring\n",
    "eta = .628\n",
    "gma = .9\n",
    "epis = 1000\n",
    "rev_list = [] # rewards per episode calculate\n",
    "\n",
    "# 3. Q-learning Algorithm\n",
    "for i in range(epis):\n",
    "    # Reset environment\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    \n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 99:\n",
    "        env.render()\n",
    "        display.clear_output(wait=True)\n",
    "        j+=1\n",
    "        \n",
    "        # Choose action from Q table\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
    "        \n",
    "        #Get new state & reward from environment\n",
    "        s1,r,d,_ = env.step(a)\n",
    "        \n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s,a] = Q[s,a] + eta*(r + gma*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    rev_list.append(rAll)\n",
    "    env.render()\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "print (\"Reward Sum on all episodes \" + str(sum(rev_list)/epis))\n",
    "print (\"Final Values Q-Table\")\n",
    "print (Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Source: https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2)\n",
    "\n",
    "## Use cases\n",
    "\n",
    "Maybe the most famous one the the case of Alpha Go project, that was develop by Google, and defeated the human World Champion of the Go game. In this case the implementation of RL was complemented with Deep Learning techniques.\n",
    "\n",
    "## References\n",
    "\n",
    "- [1] Arulkumaran, K., Deisenroth, M. P., Brundage, M., & Bharath, A. A. (2017). Deep reinforcement learning: A brief survey. IEEE Signal Processing Magazine. https://doi.org/10.1109/MSP.2017.2743240\n",
    "- [2] https://gym.openai.com/\n",
    "- [3] https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
